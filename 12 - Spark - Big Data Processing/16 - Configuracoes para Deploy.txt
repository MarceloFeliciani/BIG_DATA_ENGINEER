Correção do Exercício - Deploy
##############################

Time,

A resolução deste exercício, pode ser que na sua conta tenha um desvio de +- 2 para cada uma das opções, isso é normal, mas eu sempre irei arredondar para baixo cada uma das operações quando for atribuir os valores de executor-memory e num-executors, pois não desejo que meu job exija mais de 90%, então por garantia, arredondo para baixo.

a) 20 nodes x 8 cores | 16Gb RAM

driver-memory 8G
--executor-memory ((20*16)-10%)/39 = 8G
--conf spark.yarn.driver.memoryOverhead  3G
--conf spark.yarn.executor.memoryOverhead 2
--executors-core 4
--num-executors ((20*8)-10%)/4 = 39



b) 9 nodes x 20 cores | 128Gb RAM

driver-memory 8G
--executor-memory ((9*128)-10%)/44 = 25G
--conf spark.yarn.driver.memoryOverhead  12G
--conf spark.yarn.executor.memoryOverhead 2
--executors-core 4
--num-executors ((9*20)-10%)/4 = 44



c) 6 nodes x 10 cores | 32Gb RAM – 3 Jobs em paralelo

driver-memory 8G
--executor-memory (((6*32)-10%)/4)/3 = 15G
--conf spark.yarn.driver.memoryOverhead  2G
--conf spark.yarn.executor.memoryOverhead 1
--executors-core 4
--num-executors (((6*10)-10%)/4)/3 = 4



d) 10 nodes x 16 cores | 64Gb RAM – 50 % dos recursos já utilizados

driver-memory 8G
--executor-memory (((10*64)-10%)/19)/2 = 16G
--conf spark.yarn.driver.memoryOverhead  6G
--conf spark.yarn.executor.memoryOverhead 2
--executors-core 4
--num-executors (((10*16)-10%)/4)/2 = 19