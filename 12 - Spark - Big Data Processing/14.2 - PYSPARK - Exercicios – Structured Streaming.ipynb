{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-spark:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f30adb979b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-spark:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   3 root supergroup       4702 2021-06-23 18:23 /user/feliciani/data/iris/bezdekIris.data\r\n",
      "-rw-r--r--   3 root supergroup       4702 2021-06-23 18:23 /user/feliciani/data/iris/iris.data\r\n",
      "-rw-r--r--   3 root supergroup       3067 2021-06-23 18:23 /user/feliciani/data/iris/iris.names\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/feliciani/data/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arquivos bezdekIris tem 150 linhas\n",
    "iris_bezdekIris = spark.read.csv(\"/user/feliciani/data/iris/bezdekIris.data\")\n",
    "iris.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arquivos iris tem 150 linhas\n",
    "iris_bezdekIris = spark.read.csv(\"/user/feliciani/data/iris/iris.data\")\n",
    "iris.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total com os 2 arquivos bezdekIris e iris tem 300 linhas\n",
    "iris = spark.read.csv(\"/user/feliciani/data/iris/*.data\")\n",
    "iris.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ler os arquivos csv “hdfs://namenode:8020/user/<nome>/data/iris/*.data” em modo streaming com o seguinte schema:\n",
    "\n",
    "##### sepal_length float\n",
    "##### sepal_width float\n",
    "##### petal_length float\n",
    "##### petal_width float\n",
    "##### class string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_schema = StructType()\\\n",
    "    .add(\"sepal_length\", \"float\")\\\n",
    "    .add(\"sepal_width\", \"float\")\\\n",
    "    .add(\"petal_length\", \"float\")\\\n",
    "    .add(\"petal_width\", \"float\")\\\n",
    "    .add(\"class\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(sepal_length,FloatType,true),StructField(sepal_width,FloatType,true),StructField(petal_length,FloatType,true),StructField(petal_width,FloatType,true),StructField(class,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(iris_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lendo o conteúdo de todos os arquivos .data  (listando o 5 primeiros em memória)\n",
    "\n",
    "iris = spark.read.csv(\"/user/feliciani/data/iris/*.data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aplicando o Schema criado na leitura dos dados dos arquivos .data\n",
    "\n",
    "iris = spark.read.schema(iris_schema).csv(\"/user/feliciani/data/iris/*.data\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: float (nullable = true)\n",
      " |-- sepal_width: float (nullable = true)\n",
      " |-- petal_length: float (nullable = true)\n",
      " |-- petal_width: float (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A leitura em Batch está certa, tendo o Schema definido\n",
    "\n",
    "iris = spark.read.schema(iris_schema).csv(\"/user/feliciani/data/iris/*.data\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando o Schema com o formato STREAM\n",
    "iris = spark.readStream.schema(iris_schema).csv(\"/user/feliciani/data/iris/*.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar o schema das informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: float (nullable = true)\n",
      " |-- sepal_width: float (nullable = true)\n",
      " |-- petal_length: float (nullable = true)\n",
      " |-- petal_width: float (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvar os dados no diretório “hdfs://namenode:8020/user/<nome>/stream_iris/path” e o checkpoint em “hdfs://namenode:8020/user/<nome>/stream_iris/check”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_saida = iris.writeStream.format(\"csv\")\\\n",
    "    .option(\"checkpointLocation\",\"/user/feliciani/stream_iris/check\")\\\n",
    "    .option(\"path\", \"/user/feliciani/stream_iris/path\" )\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'56049837-9fb6-4f1f-a9d0-91eecfa7d61d'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id do Streaming\n",
    "iris_saida.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56049837-9fb6-4f1f-a9d0-91eecfa7d61d',\n",
       " 'runId': 'a3aa30b2-7342-4d25-815e-368cc683313c',\n",
       " 'name': None,\n",
       " 'timestamp': '2021-07-04T21:20:49.615Z',\n",
       " 'batchId': 1,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getOffset': 5, 'triggerExecution': 5},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'FileStreamSource[hdfs://namenode:8020/user/feliciani/data/iris/*.data]',\n",
       "   'startOffset': {'logOffset': 0},\n",
       "   'endOffset': {'logOffset': 0},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'FileSink[/user/feliciani/stream_iris/path]'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostra o último processo\n",
    "iris_saida.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_saida.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar a saida no hdfs e entender como os dados foram salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-04 20:27 /user/feliciani/stream_iris/check/commits\r\n",
      "-rw-r--r--   3 root supergroup         45 2021-07-04 20:27 /user/feliciani/stream_iris/check/metadata\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-04 20:27 /user/feliciani/stream_iris/check/offsets\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-04 20:27 /user/feliciani/stream_iris/check/sources\r\n"
     ]
    }
   ],
   "source": [
    "# contém os metadados\n",
    "\n",
    "!hdfs dfs -ls /user/feliciani/stream_iris/check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-04 20:27 /user/feliciani/stream_iris/path/_spark_metadata\n",
      "-rw-r--r--   2 root supergroup       4550 2021-07-04 20:27 /user/feliciani/stream_iris/path/part-00000-fd6b9507-e8d1-4e4e-a27e-fbd293f993ab-c000.csv\n",
      "-rw-r--r--   2 root supergroup       4550 2021-07-04 20:27 /user/feliciani/stream_iris/path/part-00001-2cdb8190-4f88-4cbe-ac86-aed8e609a7ac-c000.csv\n"
     ]
    }
   ],
   "source": [
    "# contém os dados\n",
    "\n",
    "!hdfs dfs -ls /user/feliciani/stream_iris/path\n",
    "\n",
    "# para cada arquivo enviado, foi criado um novo arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mesmo conteúdo do arquivo\n",
    "\n",
    "spark.read.csv(\"/user/feliciani/stream_iris/path/part-00000-fd6b9507-e8d1-4e4e-a27e-fbd293f993ab-c000.csv\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mesma quantidade de linhas\n",
    "\n",
    "spark.read.csv(\"/user/feliciani/stream_iris/path/part-00000-fd6b9507-e8d1-4e4e-a27e-fbd293f993ab-c000.csv\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mesmo conteúdo do arquivo\n",
    "\n",
    "spark.read.csv(\"/user/feliciani/stream_iris/path/part-00001-2cdb8190-4f88-4cbe-ac86-aed8e609a7ac-c000.csv\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(\"/user/feliciani/stream_iris/path/part-00001-2cdb8190-4f88-4cbe-ac86-aed8e609a7ac-c000.csv\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
