{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Engineer SEMANTIX\n",
    "\n",
    "## Exercícios com RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-spark:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f116f50e9b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informações da sessão de spark (spark)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-spark:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informações do contexto do spark (sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrada1.txt\r\n",
      "entrada2.txt\r\n",
      "spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\r\n"
     ]
    }
   ],
   "source": [
    "# listando os arquivos que estão dentro do container jupyter-spark\n",
    "!ls /opt/spark/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080\r\n",
      "========================================\r\n",
      "20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP\r\n",
      "20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root\r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: \r\n",
      "20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\r\n",
      "20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077\r\n",
      "20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1\r\n",
      "20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms\r\n",
      "20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\r\n",
      "20/03/18 20:31:10 INFO server.Server: Started @1504ms\r\n",
      "20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}\r\n",
      "20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}\r\n",
      "20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE\r\n"
     ]
    }
   ],
   "source": [
    "# listando o conteúdo do arquivo abaixo\n",
    "\n",
    "!cat /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\n",
    "\n",
    "# arquivo de texto com logs do spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lendo arquivo RDD para textFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler com RDD o arquivo com logs do spark do diretório “/opt/spark/logs/” (\"file:///opt/spark/logs/\")\n",
    "\n",
    "logs = sc.textFile(\"file:///opt/spark/logs/spark--org.apache.spark.deploy.master.Master-1-jupyter-notebook.out\")\n",
    "\n",
    "# lendo do container do spark, então é file:///opt...\n",
    "# se fosse do HDFS seria, hdfs:///user/..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Com uso de RDD faça as seguintes operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Contar a quantidade de linhas\n",
    "\n",
    "logs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Visualizar a primeira linha\n",
    "\n",
    "logs.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080',\n",
       " '========================================',\n",
       " '20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostra as 5 primeiras posições em memória\n",
    "\n",
    "logs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark Command: /opt/java/bin/java -cp /etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/* -Xmx1g org.apache.spark.deploy.master.Master --host localhost --port 7077 --webui-port 8080',\n",
       " '========================================',\n",
       " '20/03/18 20:31:09 INFO master.Master: Started daemon with process name: 1087@jupyter-notebook',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for TERM',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for HUP',\n",
       " '20/03/18 20:31:09 INFO util.SignalUtils: Registered signal handler for INT',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls to: root',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing view acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: Changing modify acls groups to: ',\n",
       " '20/03/18 20:31:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'sparkMaster' on port 7077.\",\n",
       " '20/03/18 20:31:10 INFO master.Master: Starting Spark master at spark://localhost:7077',\n",
       " '20/03/18 20:31:10 INFO master.Master: Running Spark version 2.4.1',\n",
       " '20/03/18 20:31:10 INFO util.log: Logging initialized @1454ms',\n",
       " '20/03/18 20:31:10 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown',\n",
       " '20/03/18 20:31:10 INFO server.Server: Started @1504ms',\n",
       " '20/03/18 20:31:10 INFO server.AbstractConnector: Started ServerConnector@5526ec85{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}',\n",
       " \"20/03/18 20:31:10 INFO util.Utils: Successfully started service 'MasterUI' on port 8080.\",\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78c62b96{/app,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1330e23c{/app/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f7fb168{/,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50e5c33c{/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d0ea1e{/static,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a362185{/app/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@222db61{/driver/kill,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO ui.MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://jupyter-notebook:8080',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@58cb287e{/metrics/master/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d2d7a89{/metrics/applications/json,null,AVAILABLE,@Spark}',\n",
       " '20/03/18 20:31:10 INFO master.Master: I have been elected leader! New state: ALIVE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUIDADOS EM PRODUÇÃO! ESSE COMANDO PODE CAUSAR UM EXCESSO DE PROCESSAMENTO.\n",
    "\n",
    "# c) Visualizar todas as linhas\n",
    "\n",
    "logs.collect()\n",
    "\n",
    "# Esse arquivos contém apenas 30 linhas, por isso esse comando foi utilizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatMap e Map\n",
    "### flatMap será usado mexer na estrutura\n",
    "### flatMap, terá uma lista com todos os dados, um em cada linha\n",
    "    \n",
    "### Map quando tiver os dados estruturados\n",
    "### Map vai ter várias listas com os elementos que foram separados, por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d) Contar a quantidade de palavras\n",
    "\n",
    "# separar as palavras da linha\n",
    "# flatMap, em cada linha fará a separação de palavras colocando um espaço e em linhas diferentes.\n",
    "# flatMap, terá uma lista com todos os RDDs, um em cada linha\n",
    "\n",
    "palavras = logs.flatMap(lambda linha: linha.split(\" \"))\n",
    "\n",
    "palavras.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e) Converter todas as palavras em minúsculas\n",
    "# map, pegará cada palavra das 268 e colocará em minúscula. Terá uma palavra por linha. Quando o MAP separar um grupo de palavras\n",
    "# colocará numa lista diferente. O MAP terá várias listas\n",
    "\n",
    "minuscula = palavras.map(lambda palavra: palavra.lower())\n",
    "\n",
    "minuscula.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark',\n",
       " 'command:',\n",
       " '/opt/java/bin/java',\n",
       " '-cp',\n",
       " '/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       " '-xmx1g',\n",
       " 'org.apache.spark.deploy.master.master',\n",
       " '--host',\n",
       " 'localhost',\n",
       " '--port']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostra as 10 primeiras posições em memória\n",
    "\n",
    "minuscula.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) Remover as palavras de tamanho menor que 2\n",
    "\n",
    "# filter, filtrará todas as palavras com comprimento maior do que 2\n",
    "\n",
    "minuscula_maior2 = minuscula.filter(lambda palavra: len(palavra) > 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consta 257 palavras, porque não tem as palavras com tamanho menor do que 2\n",
    "\n",
    "minuscula_maior2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g) Atribuir o valor de 1 para cada palavra\n",
    "\n",
    "# usando o map, todas as vezes que ver uma palavra, ela ganhará mais uma estrutura (1)\n",
    "\n",
    "palavra_1 = minuscula_maior2.map(lambda palavra: (palavra,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spark', 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionado a estrutura como número 1 para cada palavra com mais de 2 de comprimento\n",
    "palavra_1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h) Contar as palavras com o mesmo nome\n",
    "\n",
    "# juntar as palavras com o reduceByKey\n",
    "palavras_reduce = palavra_1.reduceByKey(lambda chave1, chave2: chave1 + chave2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contando. As palavras foram agrupadas, por exemplo spark que continha mais de uma vez, foi agrupada, por isso reduziu\n",
    "palavras_reduce.count()\n",
    "\n",
    "# restaram 101 palavras após a redução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.1) Visualizar em ordem alfabética\n",
    "\n",
    "# sortBy, ordenará. Foi colocado pelo indice inicial [0] Alfabético\n",
    "\n",
    "palavras_ordem = palavras_reduce.sortBy(lambda palavra: palavra[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'masterui'\", 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('--host', 1),\n",
       " ('--port', 1),\n",
       " ('--webui-port', 1),\n",
       " ('-cp', 1),\n",
       " ('-xmx1g', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('2.4.1', 1),\n",
       " ('20/03/18', 28),\n",
       " ('20:31:09', 4),\n",
       " ('20:31:10', 24),\n",
       " ('7077', 1),\n",
       " ('7077.', 1),\n",
       " ('8080', 1),\n",
       " ('8080.', 1),\n",
       " ('========================================', 1),\n",
       " ('@1454ms', 1),\n",
       " ('@1504ms', 1),\n",
       " ('acls', 5),\n",
       " ('alive', 1),\n",
       " ('and', 1),\n",
       " ('authentication', 1),\n",
       " ('been', 1),\n",
       " ('bound', 1),\n",
       " ('build', 1),\n",
       " ('changing', 4),\n",
       " ('command:', 1),\n",
       " ('daemon', 1),\n",
       " ('disabled;', 2),\n",
       " ('elected', 1),\n",
       " ('for', 3),\n",
       " ('git', 1),\n",
       " ('groups', 4),\n",
       " ('handler', 3),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('hash:', 1),\n",
       " ('have', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('hup', 1),\n",
       " ('info', 28),\n",
       " ('initialized', 1),\n",
       " ('int', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('leader!', 1),\n",
       " ('localhost', 1),\n",
       " ('logging', 1),\n",
       " ('master', 1),\n",
       " ('master.master:', 4),\n",
       " ('masterwebui', 1),\n",
       " ('modify', 4),\n",
       " ('name:', 1),\n",
       " ('new', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('permissions:', 4),\n",
       " ('port', 2),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('root', 2),\n",
       " ('running', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('server.server:', 2),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('service', 2),\n",
       " ('set()', 1),\n",
       " ('set();', 1),\n",
       " ('set(root);', 2),\n",
       " ('signal', 3),\n",
       " ('spark', 3),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('started', 15),\n",
       " ('starting', 1),\n",
       " ('state:', 1),\n",
       " ('successfully', 2),\n",
       " ('term', 1),\n",
       " ('timestamp:', 1),\n",
       " ('to:', 4),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('unknown', 1),\n",
       " ('unknown,', 1),\n",
       " ('users', 2),\n",
       " ('util.log:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('util.utils:', 2),\n",
       " ('version', 1),\n",
       " ('view', 4),\n",
       " ('with', 5)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listou inicialmente os símbolos\n",
    "\n",
    "palavras_ordem.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.2) Visualizar em ordem numérica\n",
    "\n",
    "# sortBy, ordenará. Foi colocado pelo indice inicial [1] numérica\n",
    "\n",
    "palavras_ordem = palavras_reduce.sortBy(lambda palavra: palavra[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'masterui'\", 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('--host', 1),\n",
       " ('--port', 1),\n",
       " ('--webui-port', 1),\n",
       " ('-cp', 1),\n",
       " ('-xmx1g', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('2.4.1', 1),\n",
       " ('20/03/18', 28),\n",
       " ('20:31:09', 4),\n",
       " ('20:31:10', 24),\n",
       " ('7077', 1),\n",
       " ('7077.', 1),\n",
       " ('8080', 1),\n",
       " ('8080.', 1),\n",
       " ('========================================', 1),\n",
       " ('@1454ms', 1),\n",
       " ('@1504ms', 1),\n",
       " ('acls', 5),\n",
       " ('alive', 1),\n",
       " ('and', 1),\n",
       " ('authentication', 1),\n",
       " ('been', 1),\n",
       " ('bound', 1),\n",
       " ('build', 1),\n",
       " ('changing', 4),\n",
       " ('command:', 1),\n",
       " ('daemon', 1),\n",
       " ('disabled;', 2),\n",
       " ('elected', 1),\n",
       " ('for', 3),\n",
       " ('git', 1),\n",
       " ('groups', 4),\n",
       " ('handler', 3),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('hash:', 1),\n",
       " ('have', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('hup', 1),\n",
       " ('info', 28),\n",
       " ('initialized', 1),\n",
       " ('int', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('leader!', 1),\n",
       " ('localhost', 1),\n",
       " ('logging', 1),\n",
       " ('master', 1),\n",
       " ('master.master:', 4),\n",
       " ('masterwebui', 1),\n",
       " ('modify', 4),\n",
       " ('name:', 1),\n",
       " ('new', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('permissions:', 4),\n",
       " ('port', 2),\n",
       " ('process', 1),\n",
       " ('registered', 3),\n",
       " ('root', 2),\n",
       " ('running', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('server.server:', 2),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " ('service', 2),\n",
       " ('set()', 1),\n",
       " ('set();', 1),\n",
       " ('set(root);', 2),\n",
       " ('signal', 3),\n",
       " ('spark', 3),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('started', 15),\n",
       " ('starting', 1),\n",
       " ('state:', 1),\n",
       " ('successfully', 2),\n",
       " ('term', 1),\n",
       " ('timestamp:', 1),\n",
       " ('to:', 4),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('unknown', 1),\n",
       " ('unknown,', 1),\n",
       " ('users', 2),\n",
       " ('util.log:', 1),\n",
       " ('util.signalutils:', 3),\n",
       " ('util.utils:', 2),\n",
       " ('version', 1),\n",
       " ('view', 4),\n",
       " ('with', 5)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordem numérica\n",
    "palavras_ordem.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.3) Visualizar em ordem numérica invertida\n",
    "\n",
    "# sortBy, ordenará. Foi colocado pelo indice inicial [1] numérica com um sinal de menos na frente\n",
    "\n",
    "palavras_ordem = palavras_reduce.sortBy(lambda palavra: -palavra[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('7077', 1),\n",
       " ('--webui-port', 1),\n",
       " ('8080', 1),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('term', 1),\n",
       " ('int', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('set();', 1),\n",
       " ('set()', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('starting', 1),\n",
       " ('master', 1),\n",
       " ('version', 1),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('timestamp:', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('unknown', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('masterwebui', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('have', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('state:', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('-xmx1g', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('--host', 1),\n",
       " ('localhost', 1),\n",
       " ('--port', 1),\n",
       " ('========================================', 1),\n",
       " ('name:', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('hup', 1),\n",
       " ('authentication', 1),\n",
       " ('7077.', 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('running', 1),\n",
       " ('initialized', 1),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('@1504ms', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('8080.', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('bound', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('and', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('been', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordem númerica INVERTIDA\n",
    "palavras_ordem.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j) Visualizar em ordem decrescente a quantidade de palavras\n",
    "\n",
    "# sortBy, ordenará. Foi colocado pelo indice inicial [1] numérica com um sinal de menos na frente\n",
    "\n",
    "palavras_ordem_qtd = palavras_reduce.sortBy(lambda palavra: palavra[1],False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2),\n",
       " ('/opt/java/bin/java', 1),\n",
       " ('7077', 1),\n",
       " ('--webui-port', 1),\n",
       " ('8080', 1),\n",
       " ('daemon', 1),\n",
       " ('process', 1),\n",
       " ('term', 1),\n",
       " ('int', 1),\n",
       " ('securitymanager:', 1),\n",
       " ('set();', 1),\n",
       " ('set()', 1),\n",
       " (\"'sparkmaster'\", 1),\n",
       " ('starting', 1),\n",
       " ('master', 1),\n",
       " ('version', 1),\n",
       " ('2.4.1', 1),\n",
       " ('util.log:', 1),\n",
       " ('logging', 1),\n",
       " ('@1454ms', 1),\n",
       " ('jetty-9.3.z-snapshot,', 1),\n",
       " ('timestamp:', 1),\n",
       " ('git', 1),\n",
       " ('hash:', 1),\n",
       " ('unknown', 1),\n",
       " ('o.s.j.s.servletcontexthandler@1330e23c{/app/json,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@44d0ea1e{/static,null,available,@spark}', 1),\n",
       " ('masterwebui', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3d2d7a89{/metrics/applications/json,null,available,@spark}',\n",
       "  1),\n",
       " ('have', 1),\n",
       " ('leader!', 1),\n",
       " ('new', 1),\n",
       " ('state:', 1),\n",
       " ('command:', 1),\n",
       " ('-cp', 1),\n",
       " ('/etc/spark/:/opt/spark/jars/*:/etc/hadoop/:/etc/hadoop/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/tools/lib/*',\n",
       "  1),\n",
       " ('-xmx1g', 1),\n",
       " ('org.apache.spark.deploy.master.master', 1),\n",
       " ('--host', 1),\n",
       " ('localhost', 1),\n",
       " ('--port', 1),\n",
       " ('========================================', 1),\n",
       " ('name:', 1),\n",
       " ('1087@jupyter-notebook', 1),\n",
       " ('hup', 1),\n",
       " ('authentication', 1),\n",
       " ('7077.', 1),\n",
       " ('spark://localhost:7077', 1),\n",
       " ('running', 1),\n",
       " ('initialized', 1),\n",
       " ('build', 1),\n",
       " ('unknown,', 1),\n",
       " ('@1504ms', 1),\n",
       " ('server.abstractconnector:', 1),\n",
       " ('serverconnector@5526ec85{http/1.1,[http/1.1]}{0.0.0.0:8080}', 1),\n",
       " (\"'masterui'\", 1),\n",
       " ('8080.', 1),\n",
       " ('o.s.j.s.servletcontexthandler@78c62b96{/app,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@3f7fb168{/,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@50e5c33c{/json,null,available,@spark}', 1),\n",
       " ('o.s.j.s.servletcontexthandler@2a362185{/app/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('o.s.j.s.servletcontexthandler@222db61{/driver/kill,null,available,@spark}',\n",
       "  1),\n",
       " ('ui.masterwebui:', 1),\n",
       " ('bound', 1),\n",
       " ('0.0.0.0,', 1),\n",
       " ('and', 1),\n",
       " ('http://jupyter-notebook:8080', 1),\n",
       " ('o.s.j.s.servletcontexthandler@58cb287e{/metrics/master/json,null,available,@spark}',\n",
       "  1),\n",
       " ('been', 1),\n",
       " ('elected', 1),\n",
       " ('alive', 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_ordem_qtd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k) Remover as palavras, com a quantidade de palavras > 1\n",
    "\n",
    "# palavra[1] indica para pegar as palavras com quantidades igual a 1\n",
    "\n",
    "palavras_ordem_filtro = palavras_ordem_qtd.filter(lambda palavra: palavra[1] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20/03/18', 28),\n",
       " ('info', 28),\n",
       " ('20:31:10', 24),\n",
       " ('started', 15),\n",
       " ('handler.contexthandler:', 9),\n",
       " ('with', 5),\n",
       " ('spark.securitymanager:', 5),\n",
       " ('acls', 5),\n",
       " ('20:31:09', 4),\n",
       " ('master.master:', 4),\n",
       " ('groups', 4),\n",
       " ('permissions:', 4),\n",
       " ('changing', 4),\n",
       " ('view', 4),\n",
       " ('to:', 4),\n",
       " ('modify', 4),\n",
       " ('registered', 3),\n",
       " ('spark', 3),\n",
       " ('util.signalutils:', 3),\n",
       " ('signal', 3),\n",
       " ('handler', 3),\n",
       " ('for', 3),\n",
       " ('root', 2),\n",
       " ('disabled;', 2),\n",
       " ('set(root);', 2),\n",
       " ('successfully', 2),\n",
       " ('service', 2),\n",
       " ('server.server:', 2),\n",
       " ('users', 2),\n",
       " ('util.utils:', 2),\n",
       " ('port', 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a menor é com comprimento 2\n",
    "\n",
    "palavras_ordem_filtro.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l) Salvar o RDD no diretorio do HDFS /user/<seu-nome>/logs_count_word\n",
    "\n",
    "palavras_ordem_filtro.saveAsTextFile(\"/user/feliciani/logs_count_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-06-28 15:12 /user/feliciani/logs_count_word/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        517 2021-06-28 15:12 /user/feliciani/logs_count_word/part-00000\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-06-28 15:12 /user/feliciani/logs_count_word/part-00001\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/feliciani/logs_count_word\n",
    "\n",
    "# criou o arquivo com 2 partições no HDFS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
