{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Streaming com Kafka e Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Ler o tópico do kafka “topic-kvspark” em modo batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_read = spark.read\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "    .option(\"subscribe\",\"topic-kvspark\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualizar o schema do tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_read.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualizar o tópico com o campo key e value convertidos em string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|key|               value|\n",
      "+---+--------------------+\n",
      "|  1|                Msg1|\n",
      "|  1|                Msg1|\n",
      "|  3|                Msg3|\n",
      "|   |                Msg1|\n",
      "|  3|                Msg3|\n",
      "|  1|             Marcelo|\n",
      "|  3|Estudo de domingo...|\n",
      "|  1|             Marcelo|\n",
      "|  3|Estudo de domingo...|\n",
      "|  1|             Marcelo|\n",
      "|  3|Estudo de domingo...|\n",
      "|  2|                Msg2|\n",
      "|  2|                Msg2|\n",
      "|  2|           Feliciani|\n",
      "|  2|           Feliciani|\n",
      "|  2|           Feliciani|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_string = topic_read.select(col(\"key\").cast(\"string\"),col(\"value\").cast(\"string\"))\n",
    "topic_string.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Ler o tópico do kafka “topic-kvspark” em modo streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se for preciso ler todas as mensagens desde o ínicio adicinar    .option(\"startingOffsets\",\"earliest\")\\\n",
    "# da forma abaixo, vai pegar as novas mensagens de stream\n",
    "\n",
    "topic_read_stream = spark.readStream\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "    .option(\"subscribe\",\"topic-kvspark\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Visualizar o schema do tópico em streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_read_stream.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Alterar o tópico em streaming com o campo key e value convertidos para string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_string_stream = topic_read_stream.select(col(\"key\").cast(\"string\"),col(\"value\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Salvar o tópico em streaming no tópico topic-kvspark-output a cada 5 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvará esse topico (topic-kvspark-output) lá no broker do Kafka\n",
    "topic_string_stream_output = topic_string_stream.writeStream\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "    .option(\"topic\",\"topic-kvspark-output\")\\\n",
    "    .option(\"checkpointLocation\",\"/user/feliciani/kafka_checkpoint\")\\\n",
    "    .trigger(continuous='5 seconds')\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Initializing sources',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_string_stream_output.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que fosse criado este novo tópico no Kafka foi necessário criar novas mensagens no Kafka Producer para que o Spark fizesse a captura, realizasse o processamento e gravasse o novo tópico no Kafka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic criado com sucesso no Kafka. Print do Kafka abaixo:\n",
    "#### bash-4.4# kafka-topics.sh --bootstrap-server kafka:9092 --list\n",
    "#### --topic-kvspark\n",
    "#### --topic-spark\n",
    "#### __consumer_offsets\n",
    "#### topic-kvspark\n",
    "#### topic-kvspark-output\n",
    "#### topic-spark\n",
    "#### bash-4.4#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Salvar o tópico na pasta hdfs://namenode:8020/user/<nome>/Kafka/topic-kvspark-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada aquivo que chegar, será salvo no HDFS\n",
    "\n",
    "topic_string_stream_output = topic_string_stream.writeStream\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"checkpointLocation\",\"/user/feliciani/kafka_checkpoint1\")\\\n",
    "    .option(\"path\",\"/user/feliciani/kafka/topic-kvspark-output\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-05 13:05 /user/feliciani/kafka/topic-kvspark-output/_spark_metadata\r\n",
      "-rw-r--r--   2 root supergroup          0 2021-07-05 13:05 /user/feliciani/kafka/topic-kvspark-output/part-00000-1cf3eb20-3799-4ba1-9408-2db1e58d4435-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "# arquivo gravado no HDFS (hdfs://namenode:8020)\n",
    "\n",
    "!hdfs dfs -ls /user/feliciani/kafka/topic-kvspark-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteúdo do arquivo está em string\n",
    "\n",
    "!hdfs dfs -cat /user/feliciani/kafka/topic-kvspark-output/part-00000-1cf3eb20-3799-4ba1-9408-2db1e58d4435-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
